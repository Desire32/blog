Чтож это мой первый пост, блог так называемый, никогда этим не занимался но начнем, буду писать сам.
В этом блогке я расскажу о своей первой исследовательской работе, о чем она была и как у меня получилось ее довершить.
Все началось после окончания обучения моего второго года в университете и я искал, чем бы заняться следующее лето, как обычно это делают студенты, набраться скажем так опыта. 
Я начал отсылать свое резюме (Оглялдываясь назад смотря как я писал в нем ничего кроме знания html/css/js хочется смеятся, но все мы там были), также разговаривал с учителями по университету которые были very helpful to me.
Так я начал свое близкое знакомство со своим course leader, Louis Nisiotis, в один такой день он искал студента который бы взял на себя работу по изучению строения Nvidia Chat RTX, о ее структуре и как бы она могла бы использоаться для unity. Такова была первоначальная идея но конечно уже у меня не было никакого опыта работа с инфраструктурой (я даже не знал как пользоваться postman и делать curl, come on), но я был полон энтузиазма.
Началось все как если бы градиентный спуск не был бы оптимизирован и был бы сломан, curve of learning была очень сложной, повторюсь я ничего не знал о ai, о providers, мои знания ограничивалась открытием часта с chatgpt, ни о каких других средствах кроме open ai я и не знал подавно.
Вследствие чего я начал идти напролом, я полез в код nvidia chat rtx, пытался написать какой то api чтобы подключить эту громадину к unity, писал workarounds, хранения outputs в txt и последующая загрузка в unity scene. Можете верить.
Параллельно с этим я начал свое знакомство с ollama providers, был очень удивлен работой gen модели в консоли, но применения я ей не смог найти, так как задача проекта была иметь хранение переписки пользователей, что закрытая архитектура ollama не позволяла.
После месяца ломания головы и тестирований мне довелось наткнуться на скрипт человека, который сделал возможным подхватывать responses chat rtx и делать с ними что угодно. [НАЗВАНИЕ СКРИПТА/ ссылка]. И после некоторых махинаций я наконец то смог получить свой MVP, working solution. Оборачиваясь назад понимаю, что использовать такую махину как Chatrtx для обыкновенной истории переписок было словно пригнать танк на спортивную гонку.
Я начал думать об этом, осмыслевать, я понимал что моя система не эффективна (я люблю все оптимизировать) и начал искать другие способы, переделания проекта, его замены. Идея проекта также заключалась не только в храпнение истории сообщений пользователей, но и чтобы это работало глобально (Я придумал выкладывать python script на сервера aws ( где мне также довелось познакомиться с архитектурой ec2), но впоследствии мы от этой идеи отказались и сфокусировались на локальной сети в зоне университета для студентов).
Я начал свое углубленное изученния программирования с golang, очень нравился этот язык, и guess what, во время этого проекта везде и всюду я старался сделать это на golang, в бой пошли protocol buffers, grpc, для того чтобы ускорить передачу сообщений для пользователи (от того что я поменяю гусеницы танка на колеса, танком он быть не перестанет), что не дало ничего проекту но дало мне оьширный знания в архитектуре и посмтроении решений.
Работа длилась с Лета 2024, и закончилась в Январе 2025. Так что все мои эскперименты в лаборатории закончились к Ноябрю, и я начал думать о новом подходе, а не straight forward one, который я наработал на своем незнании.
После чего я нактнулся на такой provider, как langchain, и oh boy, понеслось. изучения порталов huggingface, обширный мир который всегда был скрыт и недоступен для меня, llama-index, vllm, и тд. Я остановил свое внимание на langchain и сфокусировался на нем.
С использованием langchain и ollama поддержкой (кой опыт с ней у меня уже был) я начал строительство pipeline python script, который выглядит совершенно примитивно, пара строчек интеграции api, указание custom prompt template поведения модели, но тогда для меня мне казалось что я занимаюсь rocket science.
И после череды взлетов и падений, pipeline был готов. Оставалась только одна проблема, как мне сохранять историю сообщений пользователей и как именно я собираюсь это делать? Было несколько способов, был способ работы с redis и хранения истории прямо в памяти, но на нашей системе были проблемы с виртуализацией и нам пришлось от этой идеи отказаться.  Работать с передачей информации из текстовых файлов мы также не могли себе дальше продолжить, because of obivus reason. Должен сказать, что план был ограничить знания модели in an area of given knowledge, то есть RAG approach.
Мое внимание привлек портал Upstash, который позволял хранить информацию в RAG, но удаленно, ты просто также подключаешь api и вся твоя информация о каждой сессии и каждом пользователи хранится на сервере, что и было прорывом в нашей работе (Интеграции модели была моей задачей).

И в конце концов, после публикации оставалось ждать и надеяться, впечателния, страх, третьекурсник который вне программы решил поучаствовать в ислледовательских работах, которые обычно для четвертого курса и не являются даже частью программы, fingers crossed. и после долгого нервного ожидания я узнаю что работа была принята, acceptance rate 21%! это было незабываемый процесс, и хочу сказать спасибо lOUIS за его подход к обучению новым вещам, он доверился мне и грубо говоря дал все ресурсы котоыре мне были нужны, без какой то наводки. Я узнал что такое настоящая работа в укомманде, дедлайны, и сенрьещная игра. 


INTRO:
Моя исследовательская работа была частью более крупного проекта, который мы делали в университете — создание интеллектуальной музейной системы в метавселенной для сохранения и популяризации культурного наследия. Если говорить проще, мы пытались сделать такой виртуальный музей, где посетители могли бы не просто смотреть на экспонаты, но и общаться с ними — в прямом смысле — через умные ИИ-ассистенты.
В основе лежала архитектура Cyber-Physical-Social Systems (CPSS) — это такие системы, которые объединяют физический мир, цифровую среду и социальные взаимодействия. Мы хотели, чтобы музей реагировал на посетителя: знал, где он находится, какие экспонаты уже видел, и мог вести связную, контекстную беседу, как хороший экскурсовод. Для этого мы тестировали разные Large Language Models — GPT-4, Mistral и другие — и проверяли их по четырем важным критериям: точность фактов, уместность в контексте, безопасность (никаких культурно-нечувствительных ответов) и «человечность» общения.

MY ROAD:
По сути, мы занимались тем, чтобы соединить передовые AI-модели с иммерсивной метавселенной, сделать всё это безопасным, интересным и полезным для образовательных целей. Ну и, как водится, по дороге пришлось изобретать кучу обходных решений и копать глубоко в архитектуру, что и стало моим главным полем экспериментов.
После второго курса университета я, как и многие студенты, начал искать, чем заняться летом, чтобы набраться опыта. Рассылал резюме (в котором было всего «знаю HTML/CSS/JS» — сейчас смешно, но тогда казалось достаточным) и общался с преподавателями, пока не познакомился ближе со своим course leader, Louis Nisiotis. Он предложил заняться исследованием устройства Nvidia Chat RTX и попробовать интегрировать его с Unity. Я никогда не работал с подобной инфраструктурой, не знал ни про Postman, ни про curl, но энтузиазм зашкаливал. Старт был резким и болезненным — learning curve оказался крутым, ведь мои знания об AI ограничивались только ChatGPT. Тем не менее, я лез в код, пытался писать API, делал обходные пути через сохранение ответов в txt и загрузку их в Unity, параллельно пробуя Ollama, которая впечатлила, но не подходила из-за невозможности хранить историю переписки.

После месяца мучений я наткнулся на скрипт, который позволял подхватывать ответы Chat RTX и работать с ними свободно, что дало первый MVP. Правда, это было как пригнать танк на спортивную гонку — мощно, но неэффективно. Мы хотели хранить историю сообщений и сделать систему глобальной, даже думали о запуске Python-скрипта на AWS EC2, но в итоге решили оставить всё в локальной сети университета. В процессе я увлекся Go, экспериментировал с protocol buffers и gRPC, что не ускорило проект, но сильно расширило мои знания об архитектуре.
К ноябрю 2024 стало ясно, что нужен другой подход. Так я вышел на LangChain и открыл для себя HuggingFace, LlamaIndex, vLLM. Опыт с Ollama помог построить первый pipeline на Python с кастомным prompt template — простая интеграция API, но тогда для меня это было как rocket science. Осталась последняя проблема — где хранить историю переписки. Redis отпал из-за виртуализации, текстовые файлы — по очевидным причинам. Так я пришел к Upstash, который позволил хранить данные удаленно в рамках RAG-подхода. Это стало финальной точкой проекта, который длился с лета 2024 до января 2025 и подарил мне не только результат, но и глубокое понимание AI-интеграций, инструментов и архитектурных решений.

END:
ChatGPT сказал:
В итоге, после завершения работы оставалось только ждать и надеяться. Смесь восторга и страха — ведь я, будучи третьекурсником, решился участвовать в исследовательском проекте, который обычно выполняют студенты четвертого курса и который даже не входил в мою учебную программу. Fingers crossed.
После долгого и нервного ожидания пришла новость: работа принята! И это при acceptance rate всего 21%. Это был незабываемый опыт. Хочу отдельно поблагодарить Louis за его подход к обучению — он доверился мне, буквально дал все необходимые ресурсы, не диктуя каждый шаг. Благодаря этому я по-настоящему прочувствовал, что значит работать в команде, соблюдать жесткие дедлайны и играть в «серьезную игру» науки.