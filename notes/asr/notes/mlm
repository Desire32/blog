начну с описания того, зачем нам собственно понадобилась mlm, как мы пришли к этой идеи, и как это навело нас на использование kenlm.

началось все в первой недели, мы, сидя грубо говоря с голой задницей, думали, как же нам запустить процесс, первая мысль -> нам нужен датасет. где нам его взять? так как мы все вместе обучались благодаря друг другу, на начальном этапе никто не знал как и что делается. поэтому мы решили поступить простым методом, мы купили словарь кипрского диалекта из библиотеки и отсерокопировали его в последствии.
почистив и приведя в последствии полученные данные, мы получили первый кипрский материал! но что было с ним делать, непонятно. 
после чего мы наткнулись на такую интересную идею от Amazon в их исследовательской работе под названием RescoreBERT: Discriminative Speech Recognition Rescoring with BERT, ссылка [https://arxiv.org/abs/2202.01094], где был встроен некий фильтр в виде предобученной mlm , которая бы помогала на выходе фильтровать то что услышала asr.
задача о постройке моделей лежала исключительно на мне, и я полез в эти дебри (по итогу у меня даже получилась вполне сносная mlm модель, которая находится в открытом доступе для каждого)
вообще, грубо говоря, это являлось необязательной идеей, а лишь моей инициативой (не пропадать ведь такому добру, словарю на 30000 кипрских пар), но получилось у меня это лишь к концу третьей недели, половина времени была израсходавана и было принятно решение отказаться от попытки обьединить эти две вещи. (потому что мы трезво понимали, это не наш уровень)
я думаю, вы уже представили нашу реакцию, когда я совершенно случайно раскопал kenlm, простой но эффективный инструмент работающий с ngrams, буквально то что нам было нужно. я потратил на изучение и имплементацию его 4 дня, после чего весь кипрский диалект был превращен в матрицы и подан asr (забегая вперед скажу, что добавление kenlm в архитектуру дало прирост в точности для wer, снизив на 7 процентов,  чему я был очень рад)